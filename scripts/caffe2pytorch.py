import numpy as np
import os.path
import os
import json
import scipy
import argparse
import math
# from sklearn.preprocessing import normalize
from scipy import misc

import cv2
import matplotlib.pyplot as plt
import pickle as pkl

# caffe_root = 'PATH_TO_YOUR_CAFFE/caffe-rsdnet/'  # # MODIFY PATH for YOUR SETTING
# import sys
# sys.path.insert(0, caffe_root + 'python')

caffe_root = '/temp_disk2/leise/ml/deeplab_v2/deeplab-public-ver2/'  # # MODIFY PATH for YOUR SETTING
import sys
sys.path.insert(0, caffe_root + 'python')

import caffe

# Import arguments
parser = argparse.ArgumentParser()
parser.add_argument('--model', type=str, required=True)
parser.add_argument('--weights', type=str, required=True)
parser.add_argument('--iter', type=int, required=True)
args = parser.parse_args()

# caffe.set_mode_cpu()

caffe.set_mode_gpu()
caffe.set_device(3)   # Set the gpu_id 

net = caffe.Net(args.model,
                args.weights,
                caffe.TEST)


fname = "/home/leise/ml/tmm_ref/rank_related/rsdnet/scripts/inference/test_salsod.txt"
save_folder = "/home/ml/tmm_ref/rank_related/rsdnet/saliency_maps_salsod_rsdnet_1/"

"""
reference: https://blog.csdn.net/DumpDoctorWang/article/details/88732919 
"""

# dict of param name and weight
name_weights = {}
# dict of param information
keys = open('keys.txt', 'w')
keys.write('generated by rsdnet\n\n')

for param_name in net.params.keys():
    name_weights[param_name] = {}
    layer_params = net.params[param_name]
    if len(layer_params) == 1: # deconv
        weight = layer_params[0].data
        name_weights[param_name]['weight'] = weight

        print('%s:\t%s (weight)' % (param_name, weight.shape))
        keys.write('%s:\t%s (weight)\n' % (param_name, weight.shape))

    elif len(layer_params) == 2: # conv or fc: weight and bias
        weight = layer_params[0].data
        name_weights[param_name]['weight'] = weight
        
        bias = layer_params[1].data
        name_weights[param_name]['bias'] = bias

        print('%s:\n\t%s (weight)' % (param_name, weight.shape))
        print('\t%s (bias)' % str(bias.shape))
        keys.write('%s:\t%s (weight)\t%s (bias)\n' % (param_name, weight.shape, str(bias.shape)))
    elif len(layer_params) == 3: # BatchNorm layer: running_mean running_var and scale
        running_mean = layer_params[0].data  # running_mean
        name_weights[param_name]['running_mean'] = running_mean / layer_params[2].data
        running_var = layer_params[1].data  # running_var
        name_weights[param_name]['running_var'] = running_var/layer_params[2].data

        print('%s:\n\t%s (running_var)' % (param_name, running_var.shape),)
        print('\t%s (running_mean)' % str(running_mean.shape))
        keys.write('%s:\t%s (running_var)\t%s (running_mean)\n' % (param_name, running_var.shape, str(running_mean.shape)))
    else:
        raise RuntimeError("unexpected layer \n")
keys.close()

with open('weights.pkl', 'wb') as f:
    pkl.dump(name_weights, f, protocol=2)

#   python caffe2pytorch.py --model ../../models/test_rsdnet.prototxt --weights ../../models/rsdnet.caffemodel --iter 425
